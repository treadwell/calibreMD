---
title: "CalibreMD"
author: "Ken Brooks"
date: "5/11/2025"
output: html_document
---

# Setup

## Options

```{r}
# Set knitr options directly
knitr::opts_chunk$set(
  fig.pos = 'h',
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  autodep = TRUE,
  cache = TRUE,
  fig.width = 6,
  fig.asp = 0.618,
  out.width = "70%",
  fig.align = "center",
  fig.show = "hold"
)

rm(list = ls())              # remove everything in the global environment
gc() # reclaim memory

```

## Load libraries

```{r setup, include=FALSE}
library(CalibreMD)
setup_packages()
```

# Load data from SQLite to EAV table

```{r}

#dataDir <- '/Users/kbrooks/Dropbox/Books/Calibre Travel Library'
dataDir <- '/Users/kbrooks/Dropbox/Books/AI Travel Library'
#dataDir <- '/Users/kbrooks/Dropbox/Books/calbreGPT'

md_db <- find_md_db(dataDir)

eav <- md_db %>% 
  load_eav() %>% 
  explode_text_features()
```

## Explore data
```{r}
tag_counts <- eav %>% get_tag_counts()
book_summary <- eav %>% get_book_summary()
tag_summary <- eav %>% get_tag_summary()
```

# Train model

```{r}
# Debug: Check EAV data before prep_dataset
cat("Debug: EAV data summary\n")
cat("Total books in EAV:", length(unique(eav$id)), "\n")
cat("Total tags in EAV:", length(unique(eav %>% filter(feature == "tag") %>% pull(value))), "\n")

# Check tag frequencies
tag_freq <- eav %>% 
  filter(feature == "tag") %>% 
  group_by(value) %>% 
  summarize(n_books = n_distinct(id)) %>% 
  arrange(desc(n_books))

cat("Tag frequencies (top 10):\n")
print(head(tag_freq, 10))

cat("Tags with >= 10 books:", sum(tag_freq$n_books >= 10), "\n")
cat("Books with tags that have >= 10 books:", length(unique(eav %>% filter(feature == "tag") %>% filter(value %in% (tag_freq %>% filter(n_books >= 10) %>% pull(value))) %>% pull(id))), "\n")

dataset <- prep_dataset(eav)
models <- train_models(dataset)
```

# Predict on all data

```{r}
predictions_probs <- predict_tags(models, dataset)
predictions_discrete <- threshold_predictions(predictions_probs, book_id = 900, threshold = 0.9)
top_n_labels <- get_top_n_labels(predictions_probs, book_id = 900, n = 5)
print(top_n_labels)
```

## Get full set of labels from threshold

```{r}
pred_long_all <- get_label_probabilities(predictions_probs)
```

## find tags that should be added

```{r}
add_threshold <- 0.75

final_addition_recommendations <- get_recommended_add(eav, pred_long_all, add_threshold)
```


## find tags that should be deleted

```{r}
remove_threshold <- 0.01

final_removal_recommendations <- get_recommended_remove(eav, pred_long_all, remove_threshold)
```

## given a tag, what books should it be in?

```{r}
tag_name <- "rp"

final_single_tag_additions <- suggest_tag_additions(eav, pred_long_all, tag_name, prob_min = 0.5)
print(final_single_tag_additions)
```

## Get recommendations for a specific book

```{r}
# Get a sample book ID from the dataset
sample_book_id <- 40


# Get recommendations for this book
recommendations <- recommend_tags_for_book(eav, predictions_probs, book_id = sample_book_id)

print(recommendations)
```
